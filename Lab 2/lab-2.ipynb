{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Feedforward Network and Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "W = np.random.randn(1, 2)\n",
    "B = np.random.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "\n",
    "def sigm(X, W, B):\n",
    "    \"\"\"\n",
    "    Sigmoid Function, a type of activation function\n",
    "    X = inputs\n",
    "    W = weights\n",
    "    B = bias\n",
    "    \"\"\"\n",
    "    M = 1/(1 + np.exp(-(X.dot(W.T) + B)))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update rules for weights and bias\n",
    "\n",
    "\n",
    "def diff_W(X, Z, Y, B, W):\n",
    "    \"\"\"\n",
    "    Update function for weights\n",
    "    \"\"\"\n",
    "    # Calculate the derivative of the sigmoid function\n",
    "    dS = sigm(X, W, B) * (1 - sigm(X, W, B))\n",
    "\n",
    "    # Calculate the derivative of W\n",
    "    dW = (Y - Z) * dS\n",
    "\n",
    "    # Return the dot product of the inputs and weights'\n",
    "    return X.T.dot(dW)\n",
    "\n",
    "\n",
    "def diff_B(X, Z, Y, B, W):\n",
    "    \"\"\"\n",
    "    Update function for biases\n",
    "    \"\"\"\n",
    "    # Calculate the derivative for the sigmoid function\n",
    "    dS = sigm(X, W, B) * (1 - sigm(X, W, B))\n",
    "\n",
    "    # Calculate the derivative of B\n",
    "    dB = (Y - Z) * dS\n",
    "\n",
    "    return dB.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation\n",
    "# Training data\n",
    "X_train = np.random.randint(2, size=[15, 2])\n",
    "Y_train = np.array([X_train[:, 0] | X_train[:, 1]]).T\n",
    "\n",
    "# Test data\n",
    "X_test = np.random.randint(2, size=[15, 2])\n",
    "Y_test = np.array([X_test[:, 0] | X_test[:, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning process\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epoch in range(500):\n",
    "    output = sigm(X_train, W, B)\n",
    "\n",
    "    W += learning_rate * diff_W(X_train, output, Y_train, B, W).T\n",
    "    B += learning_rate * diff_B(X_train, output, Y_train, B, W)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20dcf72490f89c174da2c842e68573857612f3c1b1722e617d46dde610562cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
