{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Feedforward Network and Backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation\n",
    "# Training data\n",
    "X = np.random.randint(2, size=[50, 2])\n",
    "Z = np.array([X[:, 0] ^ X[:, 1]]).T\n",
    "\n",
    "# Test data\n",
    "X_Test = np.random.randint(2, size=[50, 2])\n",
    "Z_Test = np.array([X_Test[:, 0] ^ X_Test[:, 1]]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise weights and biases\n",
    "W1 = np.random.randn(3, 2)\n",
    "B1 = np.random.randn(3)\n",
    "W2 = np.random.randn(1, 3)\n",
    "B2 = np.random.randn(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you explain why we set the dimensions of the weights as (3, 2) and (1, 3)?\n",
    "\n",
    "The weights were set as (3, 2) and (1, 3) because the data now needs to train/test a hidden layer of 3 neurons and one final neuron, as opposed to simply one as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "\n",
    "def sigm(X, W, B):\n",
    "    \"\"\"\n",
    "    Sigmoid Function, a type of activation function\n",
    "    X = inputs\n",
    "    W = weights\n",
    "    B = bias\n",
    "    \"\"\"\n",
    "    M = 1/(1 + np.exp(-(X.dot(W.T) + B)))\n",
    "    return M\n",
    "\n",
    "\n",
    "def Forward(X, W1, B1, W2, B2):\n",
    "\n",
    "    # First Layer\n",
    "    H = sigm(X, W1, B1)\n",
    "\n",
    "    # Second Layer\n",
    "    Y = sigm(H, W2, B2)\n",
    "\n",
    "    # Return the final output and the output from the final layer\n",
    "    return Y, H\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the presence of the hidden layer, we need to use the backpropagation algorithm to update the weights.\n",
    "\n",
    "$$\n",
    "E=(z-y)^2\\\\\n",
    "w_i'=w_i+\\eta\\frac{dE}{dw_i}\\\\\n",
    "b'=b+\\eta\\frac{dE}{db}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update rules for weights and bias\n",
    "\n",
    "def diff_B2(Z, Y):\n",
    "    # Calculate the derivative of B\n",
    "    dB = (Z - Y) * Y * (1 - Y)\n",
    "\n",
    "    return dB.sum(axis=0)\n",
    "\n",
    "\n",
    "def diff_W2(H, Z, Y):\n",
    "    dW = (Z - Y) * Y * (1 - Y)\n",
    "    return H.T.dot(dW)\n",
    "\n",
    "\n",
    "def diff_W1(X, H, Z, Y, W2):\n",
    "    dZ = (Z - Y).dot(W2) * Y * (1 - Y) * H * (1 - H)\n",
    "    return X.T.dot(dZ)\n",
    "\n",
    "\n",
    "def diff_B1(Z, Y, W2, H):\n",
    "    return ((Z - Y).dot(W2) * Y * (1 - Y) * H * (1 - H)).sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'got'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m B2 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m diff_B2(Z, Y)\n\u001b[0;32m      9\u001b[0m W1 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m diff_W1(X, H, Z, Y, W2)\u001b[39m.\u001b[39mT\n\u001b[1;32m---> 10\u001b[0m B1 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m diff_B1(Z, Y, W2, H)\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m:\n\u001b[0;32m     12\u001b[0m     Accuracy \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean((Z \u001b[39m-\u001b[39m Y)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 21\u001b[0m, in \u001b[0;36mdiff_B1\u001b[1;34m(Z, Y, W2, H)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdiff_B1\u001b[39m(Z, Y, W2, H):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m ((Z \u001b[39m-\u001b[39;49m Y)\u001b[39m.\u001b[39;49mgot(W2) \u001b[39m*\u001b[39m Y \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m Y) \u001b[39m*\u001b[39m H \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m H))\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'got'"
     ]
    }
   ],
   "source": [
    "# Learning process\n",
    "learning_rate = 1e-2\n",
    "\n",
    "for epoch in range(10000):\n",
    "    Y, H = Forward(X, W1, B1, W2, B2)\n",
    "\n",
    "    W2 += learning_rate * diff_W2(H, Z, Y).T\n",
    "    B2 += learning_rate * diff_B2(Z, Y)\n",
    "    W1 += learning_rate * diff_W1(X, H, Z, Y, W2).T\n",
    "    B1 += learning_rate * diff_B1(Z, Y, W2, H)\n",
    "    if not epoch % 50:\n",
    "        Accuracy = 1 - np.mean((Z - Y)**2)\n",
    "        print(f\"Epoch: {epoch}, Accuracy: {Accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "X_Test = np.random.randint(2, size=[50, 2])\n",
    "Z_Test = np.array([X_Test[:, 0] ^ X_Test[:, 1]]).T\n",
    "Y_Test, H = Forward(X_Test, W1, B1, W2, B2)\n",
    "Accuracy = 1 - np.mean((Z_Test - Y_Test)**2)\n",
    "\n",
    "print('Testing Accuracy: ', Accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20dcf72490f89c174da2c842e68573857612f3c1b1722e617d46dde610562cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
